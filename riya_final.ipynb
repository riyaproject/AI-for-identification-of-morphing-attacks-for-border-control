{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2JShW3NJR9T"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "obScfzWUJbXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b627347c-f24c-44ab-f0ab-8744bab54686"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Define paths to your dataset\n",
        "train_path = '/content/drive/MyDrive/Riya/train4/'\n",
        "validation_path = '/content/drive/MyDrive/Riya/validation4'\n"
      ],
      "metadata": {
        "id": "B6TMZVlwJZt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation and rescaling for training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "# Rescaling for validation data\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Loading training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=4,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "# Loading validation data\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_path,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=4,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "id": "_wtQ8X_wNNg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a299b132-83fa-4d21-e69f-eb017d7bea31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4601 images belonging to 2 classes.\n",
            "Found 662 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the VGG16 model, excluding the top (output) layers\n",
        "base_model = tf.keras.applications.VGG16(include_top=False, input_shape=(256, 256, 3))\n",
        "\n",
        "# Add custom layers on top of the pre-trained model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the new model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/Riya/morphing_detection_model.h5')"
      ],
      "metadata": {
        "id": "at5qCB5MNUdg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e5a5c8-efcb-4b45-dae4-3810b00c140d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3931s\u001b[0m 3s/step - accuracy: 0.9803 - loss: 0.0706 - val_accuracy: 1.0000 - val_loss: 3.7828e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 1.1864e-06 - val_accuracy: 1.0000 - val_loss: 7.7157e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3911s\u001b[0m 3s/step - accuracy: 0.9983 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 5.7547e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.4815e-07 - val_accuracy: 1.0000 - val_loss: 4.2510e-06\n",
            "Epoch 5/10\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3835s\u001b[0m 3s/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 3.1046e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 3.8334e-06 - val_accuracy: 1.0000 - val_loss: 1.1706e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3869s\u001b[0m 3s/step - accuracy: 0.9999 - loss: 5.5922e-04 - val_accuracy: 1.0000 - val_loss: 8.1608e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 6.2528e-08\n",
            "Epoch 9/10\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3853s\u001b[0m 3s/step - accuracy: 1.0000 - loss: 7.4936e-04 - val_accuracy: 1.0000 - val_loss: 3.2049e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m1150/1150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 2.3953e-05 - val_accuracy: 1.0000 - val_loss: 7.1380e-11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model for inference\n",
        "loaded_model = load_model('/content/drive/MyDrive/Riya/morphing_detection_model.h5')"
      ],
      "metadata": {
        "id": "ZGEZL-uRNYon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77629aed-24d0-45a5-829a-f13f3d78ee77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example of making predictions\n",
        "# Assuming 'image_path' is the path to your test image\n",
        "# Upload the test image from dataset to the'check' folder to verify the results\n",
        "\n",
        "#image_path = '/content//drive/MyDrive/Riya/check/127_034.jpg'\n",
        "#image_path = '/content//drive/MyDrive/Riya/check/137_043.jpg'\n",
        "#image_path = '/content//drive/MyDrive/Riya/check/136_08.jpg'\n",
        "#image_path = '/content//drive/MyDrive/Riya/check/132_03.jpg'\n",
        "#image_path = '/content//drive/MyDrive/Riya/check/128_138.jpg'\n",
        "#image_path = '/content//drive/MyDrive/Riya/check/094_100.jpg'\n",
        "#image_path = '/content//drive/MyDrive/Riya/check/135_08.jpg'\n",
        "#image_path = '/content//drive/MyDrive/Riya/check/132_141.jpg'\n",
        "#image_path = '/content//drive/MyDrive/Riya/check/134_144.jpg'\n",
        "\n",
        "\n",
        "img = tf.keras.preprocessing.image.load_img(image_path, target_size=(256, 256))\n",
        "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "predictions = loaded_model.predict(img_array)\n",
        "print('working')\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "id": "_Rh8PxPLNcu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2072263-f70e-440c-be46-4e3bba7cb2ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903ms/step\n",
            "working\n",
            "[[1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Threshold to decide the class\n",
        "threshold = 0.5\n",
        "\n",
        "# Values based on observed outputs\n",
        "morphed_output = 1.4080911812610198e-31\n",
        "original_output = 2.6642618957997334e-30\n",
        "\n",
        "# Calculate the custom threshold\n",
        "custom_threshold = (morphed_output + original_output) / 2\n",
        "print(f'custom threshold: {custom_threshold}')\n",
        "# Get the prediction value\n",
        "prediction_value = predictions[0][0]\n",
        "\n",
        "# Determine the predicted class based on the threshold\n",
        "predicted_class = 'morphed' if prediction_value <= threshold else 'original'\n",
        "\n",
        "print(f'Prediction value: {prediction_value}')\n",
        "print(f'Predicted class: {predicted_class}')\n"
      ],
      "metadata": {
        "id": "3jxZ7pzaNhrh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36be0f89-013f-4a3d-9d24-1312b6083d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "custom threshold: 1.4025355069629177e-30\n",
            "Prediction value: 1.0\n",
            "Predicted class: original\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4zvev5b6Nmox"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}